{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Job Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how you can modify the `openeo.extra.job_management.MultiBackendJobManager` to be able to:\n",
    "\n",
    "- Postprocess your assets with Python libraries like `geopandas`, `xarray`, `rasterio`, ...\n",
    "- Create a custom name / output path for your assets\n",
    "- Write the STAC metadata to a STAC API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic example of the `MultiBackendJobManager` will be used. We will assume the user already has initialized a `JobDatabase` in Parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pystac\n",
    "import pystac_client\n",
    "import requests\n",
    "import shutil\n",
    "import xarray as xr\n",
    "\n",
    "from getpass import getpass\n",
    "from requests.auth import AuthBase\n",
    "from tempfile import NamedTemporaryFile\n",
    "from typing import List\n",
    "\n",
    "from openeo.extra.job_management import ParquetJobDatabase, MultiBackendJobManager\n",
    "\n",
    "from openeo.rest.auth.oidc import (\n",
    "    OidcClientInfo,\n",
    "    OidcProviderInfo,\n",
    "    OidcResourceOwnerPasswordAuthenticator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the user also has created a job database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend_name</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>spatial_extent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdse</td>\n",
       "      <td>2021-10-10</td>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>{'east': 13.5, 'north': 52.6, 'south': 52.55, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdse</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>{'east': 13.6, 'north': 52.7, 'south': 52.65, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  backend_name  start_date    end_date  \\\n",
       "0         cdse  2021-10-10  2021-10-20   \n",
       "1         cdse  2021-01-20  2021-01-31   \n",
       "\n",
       "                                      spatial_extent  \n",
       "0  {'east': 13.5, 'north': 52.6, 'south': 52.55, ...  \n",
       "1  {'east': 13.6, 'north': 52.7, 'south': 52.65, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./job_df.parquet')\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `ParquetJobDatabase` to be passed on the `MultiBackendJobManager` later;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParquetJobDatabase('job_db.parquet')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_db = ParquetJobDatabase(\"./job_db.parquet\")\n",
    "job_db.initialize_from_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a very simple `start_job()` callable to be passed on to the `MultiBackendJobManager`. We'll just be extracting a few Sentinel-2 bands without any processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_job(row: pd.Series, connection_provider, connection: openeo.Connection, provider) -> openeo.BatchJob:\n",
    "    \n",
    "    s2_cube = connection.load_collection(\n",
    "        collection_id=\"SENTINEL2_L2A\",\n",
    "        spatial_extent=row.spatial_extent,\n",
    "        temporal_extent=[row.start_date , row.end_date],\n",
    "        bands=[\"B02\", \"B03\", \"B04\"],\n",
    "        properties={\"eo:cloud_cover\": lambda x: x.lte(60)}\n",
    "    )\n",
    "\n",
    "    return s2_cube.create_job(\n",
    "        title=\"Example Custom Job Manager\",\n",
    "        out_format=\"netcdf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a custom job manager class `CustomJobManager` which will be a subclass of `MultiBackendJobManager`, but which will overwrite the `on_job_done()` method. This is the method which is called once an openeo batch job has been successfully finished. We'll take over the code from the `MultiBackendJobManager`, but will add some additional things like:\n",
    "\n",
    "- Being able to add postprocessing\n",
    "- Adding custom name / output path for your assets\n",
    "- Write away STAC metadata of the jobs to STAC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VitoStacApiAuthentication(AuthBase):\n",
    "    \"\"\"Class that handles authentication for the VITO STAC API. https://stac.openeo.vito.be/\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.username = kwargs.get(\"username\")\n",
    "        self.password = kwargs.get(\"password\")\n",
    "\n",
    "    def __call__(self, request):\n",
    "        request.headers[\"Authorization\"] = self.get_access_token()\n",
    "        return request\n",
    "\n",
    "    def get_access_token(self) -> str:\n",
    "        \"\"\"Get API bearer access token via password flow.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            A string containing the bearer access token.\n",
    "        \"\"\"\n",
    "        provider_info = OidcProviderInfo(\n",
    "            issuer=\"https://sso.terrascope.be/auth/realms/terrascope\"\n",
    "        )\n",
    "\n",
    "        client_info = OidcClientInfo(\n",
    "            client_id=\"terracatalogueclient\",\n",
    "            provider=provider_info,\n",
    "        )\n",
    "\n",
    "        if self.username and self.password:\n",
    "            authenticator = OidcResourceOwnerPasswordAuthenticator(\n",
    "                client_info=client_info, username=self.username, password=self.password\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Credentials are required to obtain an access token. Please set STAC_API_USERNAME and STAC_API_PASSWORD environment variables.\"\n",
    "            )\n",
    "\n",
    "        tokens = authenticator.get_tokens()\n",
    "\n",
    "        return f\"Bearer {tokens.access_token}\"\n",
    "\n",
    "\n",
    "\n",
    "class STACApiInteraction:\n",
    "    _ROOT_URL = \"https://stac.openeo.vito.be\"\n",
    "\n",
    "    def __init__(self, collection_id: str, auth: AuthBase):\n",
    "        self.collection_id = collection_id\n",
    "        self.auth = auth\n",
    "\n",
    "    def _prepare_item(self, item: pystac.Item):\n",
    "        item.collection_id = self.collection_id\n",
    "        if not item.get_links(pystac.RelType.COLLECTION):\n",
    "            item.add_link(\n",
    "                pystac.Link(rel=pystac.RelType.COLLECTION, target=item.collection_id)\n",
    "            )\n",
    "    \n",
    "    def exists(self) -> bool:\n",
    "        client = pystac_client.Client.open(self._ROOT_URL)\n",
    "        return (\n",
    "            len([c.id for c in client.get_collections() if c.id == self.collection_id])\n",
    "            > 0\n",
    "        )\n",
    "    \n",
    "    def _join_url(self, url_path: str) -> str:\n",
    "        return str(self._ROOT_URL + \"/\" + url_path)\n",
    "    \n",
    "    def add_item(self, item: pystac.Item):\n",
    "        if not self.exists():\n",
    "            self.create_collection()\n",
    "\n",
    "        self._prepare_item(item)\n",
    "\n",
    "        url_path = f\"collections/{self.collection_id}/items\"\n",
    "        response = requests.post(\n",
    "            self._join_url(url_path), auth=self.auth, json=item.to_dict()\n",
    "        )\n",
    "\n",
    "        expected_status = [\n",
    "            requests.status_codes.codes.ok,\n",
    "            requests.status_codes.codes.created,\n",
    "            requests.status_codes.codes.accepted,\n",
    "        ]\n",
    "\n",
    "        self._check_response_status(response, expected_status)\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def create_collection(self):\n",
    "        spatial_extent = pystac.SpatialExtent([[-180, -90, 180, 90]])\n",
    "        temporal_extent = pystac.TemporalExtent([[None, None]])\n",
    "        extent = pystac.Extent(spatial=spatial_extent, temporal=temporal_extent)\n",
    "\n",
    "        collection = pystac.Collection(\n",
    "            id=self.collection_id,\n",
    "            description=f\"GFMap example for CustomJobManager\",\n",
    "            extent=extent,\n",
    "        )\n",
    "\n",
    "        collection.validate()\n",
    "        coll_dict = collection.to_dict()\n",
    "\n",
    "        default_auth = {\n",
    "            \"_auth\": {\n",
    "                \"read\": [\"anonymous\"],\n",
    "                \"write\": [\"stac-openeo-admin\", \"stac-openeo-editor\"],\n",
    "            }\n",
    "        }\n",
    "\n",
    "        coll_dict.update(default_auth)\n",
    "\n",
    "        response = requests.post(\n",
    "            self._join_url(\"collections\"), auth=self.auth, json=coll_dict\n",
    "        )\n",
    "\n",
    "        expected_status = [\n",
    "            requests.status_codes.codes.ok,\n",
    "            requests.status_codes.codes.created,\n",
    "            requests.status_codes.codes.accepted,\n",
    "        ]\n",
    "\n",
    "        self._check_response_status(response, expected_status)\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def _check_response_status(\n",
    "        self, response: requests.Response, expected_status_codes: list[int]\n",
    "    ):\n",
    "        if response.status_code not in expected_status_codes:\n",
    "            message = (\n",
    "                f\"Expecting HTTP status to be any of {expected_status_codes} \"\n",
    "                + f\"but received {response.status_code} - {response.reason}, request method={response.request.method}\\n\"\n",
    "                + f\"response body:\\n{response.text}\"\n",
    "            )\n",
    "\n",
    "            raise Exception(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_path(\n",
    "    root_folder: pathlib.Path,\n",
    "    row: pd.Series,\n",
    "    asset_id: str,\n",
    ") -> pathlib.Path:\n",
    "    return root_folder / f\"{row.id}_{asset_id}\"\n",
    "\n",
    "def post_job_action(job_items: List[pystac.Item], row: pd.Series, **kwargs) -> None:\n",
    "    \"\"\"Update the netcdf files with the start and end date of the job, and then write the items to STAC API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    job_items : List[pystac.Item]\n",
    "        List of all STAC items that were created by the job\n",
    "    row : pd.Series\n",
    "        The row in the job database corresponding to the job\n",
    "    \"\"\"\n",
    "    stac_api_interaction = STACApiInteraction(\n",
    "        collection_id=\"gfmap_customjobmanager_example\",\n",
    "        auth=VitoStacApiAuthentication(\n",
    "            username=getpass(\"STAC API username: \"),\n",
    "            password=getpass(\"STAC API password: \"),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    for idx, item in enumerate(job_items):\n",
    "        item_asset_path = pathlib.Path(list(item.assets.values())[0].href)\n",
    "\n",
    "        new_attributes = {\n",
    "            \"start_date\": row.start_date,\n",
    "            \"end_date\": row.end_date,\n",
    "        }\n",
    "\n",
    "        ds = xr.open_dataset(item_asset_path)\n",
    "\n",
    "        ds = ds.assign_attrs(new_attributes)\n",
    "\n",
    "        with NamedTemporaryFile(delete=False) as temp_file:\n",
    "            ds.to_netcdf(temp_file.name)\n",
    "            shutil.move(temp_file.name, item_asset_path)\n",
    "    \n",
    "        stac_api_interaction.add_item(item)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomJobManager(MultiBackendJobManager):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  \n",
    "\n",
    "    def on_job_done(self, job: openeo.BatchJob, row: pd.Series):\n",
    "        \"\"\"When a job is done, do the following:\n",
    "        - Download the results to a directory, based on the generated_output_path callable\n",
    "        - Postprocess the assets, based on the post_job_action callable\n",
    "        - Write the STAC metadata to a STAC API\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        job : openeo.BatchJob\n",
    "            The finished openeo batch job for which to handle the results\n",
    "        row : pd.Series\n",
    "            Row in the job database corresponding to the batch job that is done\n",
    "        \"\"\"\n",
    "        job_products = {}\n",
    "        job_results = job.get_results()\n",
    "        asset_ids = [a.name for a in job_results.get_assets()]\n",
    "\n",
    "        # Download and postprocess the assets\n",
    "        for asset_id in asset_ids:\n",
    "            asset = job_results.get_asset(asset_id)\n",
    "\n",
    "            output_path = generate_output_path(self._root_dir, row, asset_id)\n",
    "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            print(f'downloading asset {asset.name} to {output_path}')\n",
    "            asset.download(output_path)\n",
    "            print('Successfully downloaded asset')\n",
    "\n",
    "            job_products[f\"{job.job_id}_{asset_id}\"] = [output_path]\n",
    "        \n",
    "        job_metadata = pystac.Collection.from_dict(job.get_results().get_metadata())\n",
    "        job_items = []\n",
    "\n",
    "        for item_metadata in job_metadata.get_all_items():\n",
    "            item = pystac.read_file(item_metadata.get_self_href())\n",
    "            asset_name = list(item.assets.values())[0].title\n",
    "            asset_path = job_products[f\"{job.job_id}_{asset_name}\"][0]\n",
    "\n",
    "            item.id = f'{row.id}_{asset_name}'\n",
    "\n",
    "            if not len(item.assets.values()) == 1:\n",
    "                raise ValueError(\"Each item should only contain one asset\")  # This is not true in general, but it is for this use case. \n",
    "\n",
    "            for asset in item.assets.values():\n",
    "                asset.href = str(\n",
    "                    asset_path\n",
    "                )  # Update the asset href to the output location set by the output_path_generator\n",
    "\n",
    "            # Add the item to the the current job items.\n",
    "            job_items.append(item)\n",
    "\n",
    "        \n",
    "        post_job_action(job_items, row)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate and run the job manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n",
      "downloading asset openEO.nc to results/j-2503201101384455b27e11bde4f31165_openEO.nc\n",
      "Successfully downloaded asset\n",
      "downloading asset openEO.nc to results/j-250320110152474986cf5219df878217_openEO.nc\n",
      "Successfully downloaded asset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'job_db persist': 7,\n",
       "             'track_statuses': 5,\n",
       "             'job_db get_by_status': 1,\n",
       "             'start_job call': 2,\n",
       "             'job get status': 4,\n",
       "             'job start': 2,\n",
       "             'job launch': 2,\n",
       "             'run_jobs loop': 5,\n",
       "             'sleep': 5,\n",
       "             'job describe': 7,\n",
       "             'job started running': 1,\n",
       "             'job finished': 2})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager = CustomJobManager(root_dir=\"./results/\")  \n",
    "connection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n",
    "manager.add_backend(\"cdse\", connection=connection, parallel_jobs=2)\n",
    "\n",
    "manager.run_jobs(start_job=start_job, \n",
    "                 job_db=job_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend_name</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>spatial_extent</th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>start_time</th>\n",
       "      <th>running_start_time</th>\n",
       "      <th>cpu</th>\n",
       "      <th>memory</th>\n",
       "      <th>duration</th>\n",
       "      <th>costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdse</td>\n",
       "      <td>2021-10-10</td>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>{'east': 13.5, 'north': 52.6, 'south': 52.55, ...</td>\n",
       "      <td>j-2503201101384455b27e11bde4f31165</td>\n",
       "      <td>finished</td>\n",
       "      <td>2025-03-20T11:01:38Z</td>\n",
       "      <td>2025-03-20T11:04:08Z</td>\n",
       "      <td>38.526273989 cpu-seconds</td>\n",
       "      <td>164888.625 mb-seconds</td>\n",
       "      <td>142 seconds</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdse</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>{'east': 13.6, 'north': 52.7, 'south': 52.65, ...</td>\n",
       "      <td>j-250320110152474986cf5219df878217</td>\n",
       "      <td>finished</td>\n",
       "      <td>2025-03-20T11:01:53Z</td>\n",
       "      <td>None</td>\n",
       "      <td>119.758183234 cpu-seconds</td>\n",
       "      <td>813414.8020833333 mb-seconds</td>\n",
       "      <td>392 seconds</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  backend_name  start_date    end_date  \\\n",
       "0         cdse  2021-10-10  2021-10-20   \n",
       "1         cdse  2021-01-20  2021-01-31   \n",
       "\n",
       "                                      spatial_extent  \\\n",
       "0  {'east': 13.5, 'north': 52.6, 'south': 52.55, ...   \n",
       "1  {'east': 13.6, 'north': 52.7, 'south': 52.65, ...   \n",
       "\n",
       "                                   id    status            start_time  \\\n",
       "0  j-2503201101384455b27e11bde4f31165  finished  2025-03-20T11:01:38Z   \n",
       "1  j-250320110152474986cf5219df878217  finished  2025-03-20T11:01:53Z   \n",
       "\n",
       "     running_start_time                        cpu  \\\n",
       "0  2025-03-20T11:04:08Z   38.526273989 cpu-seconds   \n",
       "1                  None  119.758183234 cpu-seconds   \n",
       "\n",
       "                         memory     duration  costs  \n",
       "0         164888.625 mb-seconds  142 seconds      4  \n",
       "1  813414.8020833333 mb-seconds  392 seconds      4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_db = pd.read_parquet('./job_db.parquet')\n",
    "job_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the job database, so that this example can be repeated. DON'T DO THIS IN PRODUCTION :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"./job_db.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.delete('https://stac.openeo.vito.be/collections/gfmap_customjobmanager_example', auth=VitoStacApiAuthentication(username=getpass(\"STAC API username: \"), password=getpass(\"STAC API password: \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openeo-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
