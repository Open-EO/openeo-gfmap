{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point feature extraction using GFMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by reading in the reference data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the reference data is read, the batch jobs can be prepared. The user can split the batch jobs per H3 hex, or S2 tile. The end result will be a list of geodataframes, each item in the list containing the batch jobs belonging to a certain H3/S2 tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the logging for the openeo_gfmap package\n",
    "from openeo_gfmap.manager import _log\n",
    "import logging\n",
    "\n",
    "_log.setLevel(logging.DEBUG)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "_log.addHandler(stream_handler)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s|%(name)s|%(levelname)s:  %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "# Exclude the other loggers from other libraries\n",
    "class MyLoggerFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.name == _log.name\n",
    "\n",
    "stream_handler.addFilter(MyLoggerFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vverelst/openeo/openeo-gfmap/src/openeo_gfmap/manager/job_splitters.py:60: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  polygons[\"geometry\"] = polygons.geometry.centroid\n",
      "/home/vverelst/openeo/openeo-gfmap/src/openeo_gfmap/manager/job_splitters.py:64: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  s2_grid[\"geometry\"] = s2_grid.geometry.centroid\n",
      "/home/vverelst/anaconda3/envs/openeo-gfmap/lib/python3.9/site-packages/geopandas/array.py:365: UserWarning: Geometry is in a geographic CRS. Results from 'sjoin_nearest' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from openeo_gfmap.manager.job_splitters import split_job_s2grid\n",
    "import geopandas as gpd\n",
    "\n",
    "base_df = gpd.read_file(\"https://artifactory.vgt.vito.be/artifactory/auxdata-public/gfmap/DEMO_CROPTYPE.gpkg\")\n",
    "\n",
    "split_jobs = split_job_s2grid(\n",
    "    base_df, max_points=60\n",
    ")\n",
    "\n",
    "# Remove the geometry where there are no points with the \"extract\" flag\n",
    "split_jobs = [\n",
    "    job for job in split_jobs if job.extract.any()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, from this list, a new dataframe can be constructed, where each row represents a batch job. The user can customize all the columns to be added to this job dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend_name</th>\n",
       "      <th>out_prefix</th>\n",
       "      <th>out_extension</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>s2_tile</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdse</td>\n",
       "      <td>S2-L2A-features</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>31UDS</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdse</td>\n",
       "      <td>S2-L2A-features</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>31UES</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdse</td>\n",
       "      <td>S2-L2A-features</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>31UES</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdse</td>\n",
       "      <td>S2-L2A-features</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>31UFS</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cdse</td>\n",
       "      <td>S2-L2A-features</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>31UFS</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  backend_name       out_prefix out_extension  start_date    end_date s2_tile  \\\n",
       "0         cdse  S2-L2A-features      .parquet  2020-08-30  2022-03-03   31UDS   \n",
       "1         cdse  S2-L2A-features      .parquet  2020-08-30  2022-03-03   31UES   \n",
       "2         cdse  S2-L2A-features      .parquet  2020-08-30  2022-03-03   31UES   \n",
       "3         cdse  S2-L2A-features      .parquet  2020-08-30  2022-03-03   31UFS   \n",
       "4         cdse  S2-L2A-features      .parquet  2020-08-30  2022-03-03   31UFS   \n",
       "\n",
       "                                            geometry  \n",
       "0  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "1  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "2  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "3  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "4  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openeo_gfmap import Backend \n",
    "from typing import List\n",
    "\n",
    "def create_job_dataframe(\n",
    "    backend: Backend, split_jobs: List[gpd.GeoDataFrame], prefix: str = \"S2-L2A-features\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Create a dataframe from the split jobs, containg all the necessary information to run the job.\"\"\"\n",
    "    columns = [\n",
    "        \"backend_name\",\n",
    "        \"out_prefix\",\n",
    "        \"out_extension\",\n",
    "        \"start_date\",\n",
    "        \"end_date\",\n",
    "        \"s2_tile\",\n",
    "        \"geometry\",\n",
    "    ]\n",
    "    rows = []\n",
    "    for job in split_jobs:\n",
    "        # Compute the average in the valid date and make a buffer of 1.5 year around\n",
    "        median_time = pd.to_datetime(job.valid_date).mean()\n",
    "        start_date = median_time - pd.Timedelta(days=275)  # A bit more than 9 months\n",
    "        end_date = median_time + pd.Timedelta(days=275)  # A bit more than 9 months\n",
    "        s2_tile = job.tile.iloc[0] \n",
    "        rows.append(\n",
    "            pd.Series(\n",
    "                dict(\n",
    "                    zip(\n",
    "                        columns,\n",
    "                        [\n",
    "                            backend.value,\n",
    "                            prefix,\n",
    "                            \".parquet\",\n",
    "                            start_date.strftime(\"%Y-%m-%d\"),\n",
    "                            end_date.strftime(\"%Y-%m-%d\"),\n",
    "                            s2_tile,\n",
    "                            job.to_json(),\n",
    "                        ],\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "job_df = create_job_dataframe(Backend.CDSE, split_jobs)\n",
    "\n",
    "# For the sake of example, we will only run the first 5 batch jobs\n",
    "job_df = job_df.head(5)\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the reference data is read in, and the batch jobs are split by S2 tile, the user can define which datacube has to be constructed by each batch job, i.e. which features should be calculated for each batch job. For this, the user can specify a function, which takes as input a row from the job_df and gives as output a batch job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function to create a pre-masked DataCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import openeo \n",
    "from openeo_gfmap import Backend, BackendContext, FetchType, TemporalContext\n",
    "from openeo_gfmap.fetching.s2 import build_sentinel2_l2a_extractor\n",
    "from typing import Union \n",
    "\n",
    "def masked_cube(connection: openeo.Connection,\n",
    "                 bands: List[str],\n",
    "                 temporal_extent: TemporalContext,\n",
    "                 spatial_extent: Union[geojson.FeatureCollection, dict],\n",
    "                 backend_context: BackendContext,\n",
    "                 fetch_type: FetchType):\n",
    "    \n",
    "    # Extract the SCL collection only and calculate the dilation mask\n",
    "    scl_cube_properties = {\"eo:cloud_cover\": lambda val: val <= 95.0}\n",
    "\n",
    "    scl_cube = connection.load_collection(\n",
    "        collection_id=\"SENTINEL2_L2A\",\n",
    "        bands=[\"SCL\"],\n",
    "        temporal_extent=[temporal_extent.start_date, temporal_extent.end_date],\n",
    "        spatial_extent=dict(spatial_extent) if fetch_type == FetchType.TILE else None,\n",
    "        properties=scl_cube_properties,\n",
    "    )\n",
    "\n",
    "    # Resample to 10m resolution for the SCL layer\n",
    "    scl_cube = scl_cube.resample_spatial(10)\n",
    "\n",
    "    # Compute the SCL dilation mask\n",
    "    scl_dilated_mask = scl_cube.process(\n",
    "        \"to_scl_dilation_mask\",\n",
    "        data=scl_cube,\n",
    "        scl_band_name=\"SCL\",\n",
    "        kernel1_size=17,  # 17px dilation on a 10m layer\n",
    "        kernel2_size=77,  # 77px dilation on a 10m layer\n",
    "        mask1_values=[2, 4, 5, 6, 7],\n",
    "        mask2_values=[3, 8, 9, 10, 11],\n",
    "        erosion_kernel_size=3,\n",
    "    ).rename_labels(\"bands\", [\"S2-L2A-SCL_DILATED_MASK\"])\n",
    "\n",
    "    # Create the job to extract S2\n",
    "    extraction_parameters = {\n",
    "        \"target_resolution\": 10,  \n",
    "        \"load_collection\": {\n",
    "            \"eo:cloud_cover\": lambda val: val <= 95.0,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Immediately apply the mask \n",
    "    extraction_parameters[\"pre_mask\"] = scl_dilated_mask\n",
    "\n",
    "    extractor = build_sentinel2_l2a_extractor(\n",
    "        backend_context,\n",
    "        bands=bands,\n",
    "        fetch_type=fetch_type,\n",
    "        **extraction_parameters,\n",
    "    )\n",
    "\n",
    "    return extractor.get_cube(connection, spatial_extent, temporal_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a function that performs compositing and calculates some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo_gfmap.preprocessing import median_compositing, linear_interpolation\n",
    "\n",
    "def create_datacube(\n",
    "    row: pd.Series,\n",
    "    connection: openeo.Connection,\n",
    "    provider=None,\n",
    "    connection_provider=None,\n",
    "):\n",
    "    temporal_extent = TemporalContext(row.start_date, row.end_date)\n",
    "    spatial_extent = geojson.loads(row.geometry)\n",
    "\n",
    "    backend = Backend(row.backend_name)\n",
    "    backend_context = BackendContext(backend)\n",
    "\n",
    "    # Select some bands to download (chosen at random at this point)\n",
    "    bands_to_download = [\n",
    "        \"S2-L2A-B04\",\n",
    "        \"S2-L2A-B08\",\n",
    "        \"S2-L2A-B8A\",\n",
    "        \"S2-L2A-B09\",\n",
    "        \"S2-L2A-B11\",\n",
    "        \"S2-L2A-B12\",\n",
    "    ]\n",
    "\n",
    "    fetch_type = FetchType.POINT \n",
    "\n",
    "    cube = masked_cube(connection=connection,\n",
    "                       bands=bands_to_download,\n",
    "                       temporal_extent=temporal_extent,\n",
    "                       spatial_extent=spatial_extent,\n",
    "                       backend_context=backend_context,\n",
    "                       fetch_type=fetch_type)\n",
    "    \n",
    "    # # Calculate the NDVI and add it to the cube\n",
    "    # ndvi = cube.ndvi(nir=\"S2-L2A-B08\", red=\"S2-L2A-B04\")\n",
    "    # ndvi.add_dimension(\"bands\", [\"S2-L2A-NDVI\"], \"bands\")\n",
    "    # # ndvi.rename_labels(\"bands\", [\"S2-L2A-NDVI\"])\n",
    "    # cube = cube.merge_cubes(ndvi)\n",
    "\n",
    "    # Create monthly median composites\n",
    "    cube = median_compositing(cube=cube,\n",
    "                              period=\"month\")\n",
    "    # Perform linear interpolation\n",
    "    cube = linear_interpolation(cube)\n",
    "\n",
    "    # In this case the features will be the average of the bands/NDVI, so just take the average:\n",
    "    cube = cube.reduce_dimension(dimension=\"t\", reducer=\"mean\")\n",
    "\n",
    "    # Finally, create a vector cube based on the Point geometries\n",
    "    cube = cube.aggregate_spatial(geometries=spatial_extent, reducer=\"mean\")\n",
    "\n",
    "    job_options = {\n",
    "        \"executor-memory\": \"5G\",\n",
    "        \"executor-memoryOverhead\": \"2G\",\n",
    "    }\n",
    "\n",
    "    return cube.create_job(\n",
    "        out_format=\"Parquet\",\n",
    "        title=f\"GFMAP_Feature_Extraction_S2_{row.s2_tile}\",\n",
    "        job_options=job_options\n",
    "    )\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the features to be calculated have been defined, start the GFMAPJobManager to actually start the extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the user has to define a function to generate the output path per extraction. This is a callable that takes as input the root directory, the geometry index and the row corresponding to the batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def generate_output_path(\n",
    "    root_folder: Path, geometry_index: int, row: pd.Series\n",
    "):\n",
    "    features = geojson.loads(row.geometry)\n",
    "    sample_id = features[geometry_index].properties.get(\"sample_id\", None)\n",
    "    if sample_id is None:\n",
    "        sample_id = features[geometry_index].properties[\"sampleID\"]\n",
    "\n",
    "    s2_tile_id = row.s2_tile\n",
    "    \n",
    "    subfolder = root_folder / s2_tile_id \n",
    "    return (\n",
    "        subfolder\n",
    "        / f\"{row.out_prefix}_{sample_id}{row.out_extension}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 15:55:20,517|openeo_gfmap.manager|INFO:  Starting a fresh STAC collection.\n",
      "2024-05-16 15:55:20,520|openeo_gfmap.manager|INFO:  Starting ThreadPoolExecutor with 2 workers.\n",
      "2024-05-16 15:55:20,522|openeo_gfmap.manager|INFO:  Creating and running jobs.\n",
      "2024-05-16 15:55:20,819|openeo_gfmap.manager|DEBUG:  Normalizing dataframe. Columns: Index(['backend_name', 'out_prefix', 'out_extension', 'start_date', 'end_date',\n",
      "       's2_tile', 'geometry', 'status', 'id', 'start_time', 'cpu', 'memory',\n",
      "       'duration', 'description', 'costs'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 15:57:23,800|openeo_gfmap.manager|DEBUG:  Status of job j-24051601b1ca47178f251dbfeceeb6f7 is running (on backend cdse).\n",
      "2024-05-16 15:57:27,485|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 15:58:32,942|openeo_gfmap.manager|DEBUG:  Status of job j-24051601b1ca47178f251dbfeceeb6f7 is running (on backend cdse).\n",
      "2024-05-16 15:58:39,212|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 15:59:46,773|openeo_gfmap.manager|DEBUG:  Status of job j-24051601b1ca47178f251dbfeceeb6f7 is running (on backend cdse).\n",
      "2024-05-16 15:59:50,294|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:00:57,543|openeo_gfmap.manager|DEBUG:  Status of job j-24051601b1ca47178f251dbfeceeb6f7 is running (on backend cdse).\n",
      "2024-05-16 16:01:05,576|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:02:10,626|openeo_gfmap.manager|DEBUG:  Status of job j-24051601b1ca47178f251dbfeceeb6f7 is running (on backend cdse).\n",
      "2024-05-16 16:02:12,114|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:03:14,756|openeo_gfmap.manager|DEBUG:  Status of job j-24051601b1ca47178f251dbfeceeb6f7 is running (on backend cdse).\n",
      "2024-05-16 16:03:16,469|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:04:24,159|openeo_gfmap.manager|DEBUG:  Status of job j-24051601b1ca47178f251dbfeceeb6f7 is running (on backend cdse).\n",
      "2024-05-16 16:04:24,832|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:05:41,571|openeo_gfmap.manager|DEBUG:  Status of job j-24051601b1ca47178f251dbfeceeb6f7 is running (on backend cdse).\n",
      "2024-05-16 16:05:44,211|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:06:47,666|openeo_gfmap.manager|DEBUG:  Status of job j-24051601b1ca47178f251dbfeceeb6f7 is finished (on backend cdse).\n",
      "2024-05-16 16:06:47,668|openeo_gfmap.manager|INFO:  Job j-24051601b1ca47178f251dbfeceeb6f7 finished successfully, queueing on_job_done...\n",
      "2024-05-16 16:06:48,676|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:06:53,410|openeo_gfmap.manager|DEBUG:  Generating output path for asset timeseries.parquet from job j-24051601b1ca47178f251dbfeceeb6f7...\n",
      "2024-05-16 16:07:01,337|openeo_gfmap.manager|DEBUG:  Downloaded timeseries.parquet from job j-24051601b1ca47178f251dbfeceeb6f7 -> /data/users/Public/vincent.verelst/gfmap_feature_extractions/31UDS/S2-L2A-features_2021_BE_Flanders_full_2195082011.parquet\n",
      "2024-05-16 16:07:14,007|openeo_gfmap.manager|INFO:  Adding 0 items to the STAC collection...\n",
      "2024-05-16 16:07:14,009|openeo_gfmap.manager|INFO:  Added 0 items to the STAC collection.\n",
      "2024-05-16 16:07:14,011|openeo_gfmap.manager|INFO:  Writing STAC collection for j-24051601b1ca47178f251dbfeceeb6f7 to file...\n",
      "2024-05-16 16:07:17,619|openeo_gfmap.manager|INFO:  Wrote STAC collection for j-24051601b1ca47178f251dbfeceeb6f7 to file.\n",
      "2024-05-16 16:07:17,620|openeo_gfmap.manager|INFO:  Job j-24051601b1ca47178f251dbfeceeb6f7 and post job action finished successfully.\n",
      "2024-05-16 16:08:30,084|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:08:31,047|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:09:37,350|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:09:38,220|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:10:44,953|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:10:46,921|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:11:53,342|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:11:55,169|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:13:01,031|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:13:01,994|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:14:11,942|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:14:14,395|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:15:18,043|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:15:19,636|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:16:22,453|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:16:27,207|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:17:28,380|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is running (on backend cdse).\n",
      "2024-05-16 16:17:31,924|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:18:33,127|openeo_gfmap.manager|DEBUG:  Status of job j-240516eb37e64a8989dcd2c1140ce1f6 is finished (on backend cdse).\n",
      "2024-05-16 16:18:33,128|openeo_gfmap.manager|INFO:  Job j-240516eb37e64a8989dcd2c1140ce1f6 finished successfully, queueing on_job_done...\n",
      "2024-05-16 16:18:34,389|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:18:35,508|openeo_gfmap.manager|DEBUG:  Generating output path for asset timeseries.parquet from job j-240516eb37e64a8989dcd2c1140ce1f6...\n",
      "2024-05-16 16:18:37,662|openeo_gfmap.manager|DEBUG:  Downloaded timeseries.parquet from job j-240516eb37e64a8989dcd2c1140ce1f6 -> /data/users/Public/vincent.verelst/gfmap_feature_extractions/31UES/S2-L2A-features_2021_BE_Flanders_full_756568371.parquet\n",
      "2024-05-16 16:18:44,934|openeo_gfmap.manager|INFO:  Adding 0 items to the STAC collection...\n",
      "2024-05-16 16:18:44,935|openeo_gfmap.manager|INFO:  Added 0 items to the STAC collection.\n",
      "2024-05-16 16:18:44,935|openeo_gfmap.manager|INFO:  Writing STAC collection for j-240516eb37e64a8989dcd2c1140ce1f6 to file...\n",
      "2024-05-16 16:18:45,107|openeo_gfmap.manager|INFO:  Wrote STAC collection for j-240516eb37e64a8989dcd2c1140ce1f6 to file.\n",
      "2024-05-16 16:18:45,109|openeo_gfmap.manager|INFO:  Job j-240516eb37e64a8989dcd2c1140ce1f6 and post job action finished successfully.\n",
      "2024-05-16 16:19:57,232|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:19:59,336|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:21:00,721|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:21:02,315|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:22:04,002|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is running (on backend cdse).\n",
      "2024-05-16 16:22:05,486|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:23:07,083|openeo_gfmap.manager|DEBUG:  Status of job j-240516e3ad90407ebb6bfde53a50c455 is finished (on backend cdse).\n",
      "2024-05-16 16:23:07,085|openeo_gfmap.manager|INFO:  Job j-240516e3ad90407ebb6bfde53a50c455 finished successfully, queueing on_job_done...\n",
      "2024-05-16 16:23:07,966|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:23:09,405|openeo_gfmap.manager|DEBUG:  Generating output path for asset timeseries.parquet from job j-240516e3ad90407ebb6bfde53a50c455...\n",
      "2024-05-16 16:23:10,335|openeo_gfmap.manager|DEBUG:  Downloaded timeseries.parquet from job j-240516e3ad90407ebb6bfde53a50c455 -> /data/users/Public/vincent.verelst/gfmap_feature_extractions/31UES/S2-L2A-features_2021_BE_Flanders_full_2194075736.parquet\n",
      "2024-05-16 16:23:12,197|openeo_gfmap.manager|INFO:  Adding 0 items to the STAC collection...\n",
      "2024-05-16 16:23:12,199|openeo_gfmap.manager|INFO:  Added 0 items to the STAC collection.\n",
      "2024-05-16 16:23:12,199|openeo_gfmap.manager|INFO:  Writing STAC collection for j-240516e3ad90407ebb6bfde53a50c455 to file...\n",
      "2024-05-16 16:23:12,339|openeo_gfmap.manager|INFO:  Wrote STAC collection for j-240516e3ad90407ebb6bfde53a50c455 to file.\n",
      "2024-05-16 16:23:12,340|openeo_gfmap.manager|INFO:  Job j-240516e3ad90407ebb6bfde53a50c455 and post job action finished successfully.\n",
      "2024-05-16 16:24:30,639|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:24:31,416|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:25:34,301|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:25:35,558|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:26:36,634|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:26:37,568|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:27:38,507|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:27:48,946|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:28:50,590|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:28:52,649|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:29:53,781|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:29:54,409|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:30:59,317|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:31:00,330|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:32:01,570|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:32:02,588|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:33:04,131|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:33:04,682|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:34:06,187|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:34:08,481|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:35:19,397|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:35:19,928|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:36:21,261|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:36:21,771|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:37:23,408|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:37:24,234|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:38:25,533|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:38:29,056|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:39:30,597|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:39:33,666|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:40:37,889|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:40:41,062|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is running (on backend cdse).\n",
      "2024-05-16 16:41:43,621|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:41:48,150|openeo_gfmap.manager|DEBUG:  Status of job j-2405161276c44e788ebb2d0655761e3b is finished (on backend cdse).\n",
      "2024-05-16 16:41:48,152|openeo_gfmap.manager|INFO:  Job j-2405161276c44e788ebb2d0655761e3b finished successfully, queueing on_job_done...\n",
      "2024-05-16 16:41:50,811|openeo_gfmap.manager|DEBUG:  Generating output path for asset timeseries.parquet from job j-2405161276c44e788ebb2d0655761e3b...\n",
      "2024-05-16 16:41:52,327|openeo_gfmap.manager|DEBUG:  Downloaded timeseries.parquet from job j-2405161276c44e788ebb2d0655761e3b -> /data/users/Public/vincent.verelst/gfmap_feature_extractions/31UFS/S2-L2A-features_2021_BE_Flanders_full_1532555338.parquet\n",
      "2024-05-16 16:41:55,306|openeo_gfmap.manager|INFO:  Adding 0 items to the STAC collection...\n",
      "2024-05-16 16:41:55,307|openeo_gfmap.manager|INFO:  Added 0 items to the STAC collection.\n",
      "2024-05-16 16:41:55,307|openeo_gfmap.manager|INFO:  Writing STAC collection for j-2405161276c44e788ebb2d0655761e3b to file...\n",
      "2024-05-16 16:41:55,433|openeo_gfmap.manager|INFO:  Wrote STAC collection for j-2405161276c44e788ebb2d0655761e3b to file.\n",
      "2024-05-16 16:41:55,434|openeo_gfmap.manager|INFO:  Job j-2405161276c44e788ebb2d0655761e3b and post job action finished successfully.\n",
      "2024-05-16 16:42:49,768|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:43:54,892|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:44:56,031|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is running (on backend cdse).\n",
      "2024-05-16 16:45:59,158|openeo_gfmap.manager|DEBUG:  Status of job j-2405165b7d364ff89dc96196adc633b7 is finished (on backend cdse).\n",
      "2024-05-16 16:45:59,160|openeo_gfmap.manager|INFO:  Job j-2405165b7d364ff89dc96196adc633b7 finished successfully, queueing on_job_done...\n",
      "2024-05-16 16:46:02,618|openeo_gfmap.manager|DEBUG:  Generating output path for asset timeseries.parquet from job j-2405165b7d364ff89dc96196adc633b7...\n",
      "2024-05-16 16:46:04,325|openeo_gfmap.manager|DEBUG:  Downloaded timeseries.parquet from job j-2405165b7d364ff89dc96196adc633b7 -> /data/users/Public/vincent.verelst/gfmap_feature_extractions/31UFS/S2-L2A-features_2021_BE_Flanders_full_2195427369.parquet\n",
      "2024-05-16 16:46:07,495|openeo_gfmap.manager|INFO:  Adding 0 items to the STAC collection...\n",
      "2024-05-16 16:46:07,496|openeo_gfmap.manager|INFO:  Added 0 items to the STAC collection.\n",
      "2024-05-16 16:46:07,497|openeo_gfmap.manager|INFO:  Writing STAC collection for j-2405165b7d364ff89dc96196adc633b7 to file...\n",
      "2024-05-16 16:46:07,678|openeo_gfmap.manager|INFO:  Wrote STAC collection for j-2405165b7d364ff89dc96196adc633b7 to file.\n",
      "2024-05-16 16:46:07,680|openeo_gfmap.manager|INFO:  Job j-2405165b7d364ff89dc96196adc633b7 and post job action finished successfully.\n",
      "2024-05-16 16:46:59,563|openeo_gfmap.manager|INFO:  Quitting job tracking & waiting for last post-job actions to finish.\n",
      "2024-05-16 16:46:59,565|openeo_gfmap.manager|INFO:  Exiting ThreadPoolExecutor.\n"
     ]
    }
   ],
   "source": [
    "from openeo_gfmap.manager.job_manager import GFMAPJobManager\n",
    "from openeo_gfmap.backend import cdse_connection\n",
    "\n",
    "manager = GFMAPJobManager(\n",
    "        output_dir=Path(\"/data/users/Public/vincent.verelst/gfmap_feature_extractions/\"),\n",
    "        output_path_generator=generate_output_path,\n",
    "        collection_id=\"SENTINEL2-FEATURE-EXTRACTION\",\n",
    "        collection_description=\"Sentinel-2 basic point feature extraction\",\n",
    "        poll_sleep=60,\n",
    "        n_threads=2,\n",
    "        post_job_params={},\n",
    "    )\n",
    "\n",
    "manager.add_backend(\n",
    "        Backend.CDSE.value, cdse_connection, parallel_jobs=2\n",
    "    )\n",
    "\n",
    "tracking_df_path = \"/data/users/Public/vincent.verelst/gfmap_feature_extractions/job_tracking.csv\"\n",
    "manager.run_jobs(job_df, create_datacube, tracking_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openeo-gfmap",
   "language": "python",
   "name": "openeo-gfmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
