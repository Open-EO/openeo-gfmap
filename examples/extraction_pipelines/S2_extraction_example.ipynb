{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a GFMAP full-extraction pipeline\n",
    "\n",
    "Designing of GFMAP Job DataFrames and DataCube creators functions, as well as post job-actions.\n",
    "\n",
    "Those dataframe should be containing all the necessary infromation to run a job and know where to save it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step: splitting the job\n",
    "\n",
    "Splitting the dataset of extraction in multiple job based on position is necessary to respect OpenEO limitations.\n",
    "\n",
    "This script performs a split with the H3 hexagonal grid, yielding a list of sub-geodataframes.\n",
    "\n",
    "A subtility here is that some polygons are not directly extracted (field with `extract=False`), but should be kept for post-job actions. This requirement is filled by removing sub-dataframes that do not contain any extractable polyons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the logging for the openeo_gfmap package\n",
    "from openeo_gfmap.manager import _log\n",
    "import logging\n",
    "\n",
    "_log.setLevel(logging.DEBUG)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "_log.addHandler(stream_handler)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s|%(name)s|%(levelname)s:  %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "# Exclude the other loggers from other libraries\n",
    "class MyLoggerFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.name == _log.name\n",
    "\n",
    "stream_handler.addFilter(MyLoggerFilter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 jobs before filtering empty one (no extraction)\n",
      "93 jobs after filtering empty one (no extraction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vverelst/openeo/openeo-gfmap/src/openeo_gfmap/manager/job_splitters.py:53: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  polygons[\"h3index\"] = polygons.geometry.centroid.apply(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from openeo_gfmap.manager.job_splitters import split_job_hex\n",
    "\n",
    "base_df_path = Path('./2021_EUR_DEMO_POLY_110.gpkg')\n",
    "base_df = gpd.read_file(base_df_path)\n",
    "# Splits the job using GFMAP\n",
    "split_jobs = split_job_hex(\n",
    "    base_df, max_points=500, grid_resolution=4\n",
    ")\n",
    "\n",
    "print(f'{len(split_jobs)} jobs before filtering empty one (no extraction)')\n",
    "\n",
    "# Remove the geometry where there are no points with the \"extract\" flag\n",
    "split_jobs = [\n",
    "    job for job in split_jobs if job.extract.any()\n",
    "]\n",
    "print(f'{len(split_jobs)} jobs after filtering empty one (no extraction)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second step: creating a dataframe for the GFMAP Job Manager\n",
    "\n",
    "Implementing a function that yields a `pandas.DataFrame` where each row correponds to a job.\n",
    "\n",
    "The dataframe should contain the informations required by the GFMAP Job Manager, as well as additional information used by the datacube creation function and the post-job action function.\n",
    "\n",
    "The output dataframe should be savable as a .csv file.\n",
    "\n",
    "Note: the full information of a sub-geodataframe of polygons can be saved into a row of a `pandas.DataFrame` by storing it in a row as string implementing the `geojson.FeatureCollection` interface. To convert the `geopandas.GeoDataFrame` into a stirng, simply use the `.to_json()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend_name</th>\n",
       "      <th>out_prefix</th>\n",
       "      <th>out_extension</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    backend_name out_prefix out_extension  start_date    end_date  \\\n",
       "0   cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "1   cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "2   cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "3   cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "4   cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "..           ...        ...           ...         ...         ...   \n",
       "88  cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "89  cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "90  cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "91  cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "92  cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "\n",
       "                                             geometry  \n",
       "0   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "1   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "2   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "3   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "4   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "..                                                ...  \n",
       "88  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "89  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "90  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "91  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "92  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "\n",
       "[93 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openeo_gfmap import Backend\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "def create_job_dataframe_s2(backend: Backend, split_jobs: List[gpd.GeoDataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Create a dataframe from the split jobs, containg all the necessary information to run the job.\"\"\"\n",
    "    columns = ['backend_name', 'out_prefix', 'out_extension', 'start_date', 'end_date', 'geometry']\n",
    "    rows = []\n",
    "    for job in split_jobs:\n",
    "        # Compute the average in the valid date and make a buffer of 1.5 year around\n",
    "        median_time = pd.to_datetime(job.valid_date).mean()\n",
    "        start_date = median_time - pd.Timedelta(days=275)  # A bit more than 9 months\n",
    "        end_date = median_time + pd.Timedelta(days=275)  # A bit more than 9 months\n",
    "        \n",
    "        rows.append(\n",
    "            pd.Series(\n",
    "                dict(zip(columns, [backend.value, 'S2', '.nc',  start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), job.to_json()]))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "job_df = create_job_dataframe_s2(Backend.CDSE_STAGING, split_jobs)\n",
    "\n",
    "job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend_name</th>\n",
       "      <th>out_prefix</th>\n",
       "      <th>out_extension</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdse-staging</td>\n",
       "      <td>S2</td>\n",
       "      <td>.nc</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   backend_name out_prefix out_extension  start_date    end_date  \\\n",
       "0  cdse-staging         S2           .nc  2020-08-30  2022-03-03   \n",
       "\n",
       "                                            geometry  \n",
       "0  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a subset of the jobs to test the manager, the selected jobs have a fair amount of geometries to extract\n",
    "job_df = job_df.iloc[[0]].reset_index(drop=True)\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third step: implement the datacube creator function.\n",
    "\n",
    "Implement a function to create, from the additional rows provided before, an `openeo.BatchJob` that will be used to run the job.\n",
    "\n",
    "In this case we extract Sentinel-2 data, and we remove the polygons with `extract=False` (although we keep them in the row for the post-job action.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "\n",
    "import pandas as pd\n",
    "import geojson\n",
    "\n",
    "from openeo_gfmap import TemporalContext, Backend, BackendContext, FetchType\n",
    "from openeo_gfmap.fetching import build_sentinel2_l2a_extractor\n",
    "\n",
    "\n",
    "def create_datacube_s2(row: pd.Series, connection: openeo.DataCube, provider=None, connection_provider=None) -> openeo.BatchJob:\n",
    "\n",
    "    def buffer_geometry(geometry: geojson.FeatureCollection, buffer: float) -> str:\n",
    "        gdf = gpd.GeoDataFrame.from_features(geometry).set_crs(epsg=4326)\n",
    "        utm = gdf.estimate_utm_crs()\n",
    "        gdf = gdf.to_crs(utm)\n",
    "        gdf['geometry'] = gdf.centroid.buffer(distance=buffer, cap_style=3)\n",
    "\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "        return geojson.loads(gdf.to_json())\n",
    "\n",
    "\n",
    "    def filter_extractonly_geometries(collection: geojson.FeatureCollection):\n",
    "        # Filter out geometries that do not have the field extract=True\n",
    "        features = [f for f in collection.features if f.properties.get('extract', False)]\n",
    "        return geojson.FeatureCollection(features)\n",
    "\n",
    "    start_date = row.start_date\n",
    "    end_date = row.end_date\n",
    "    temporal_context = TemporalContext(start_date, end_date)\n",
    "\n",
    "    # Get the feature collection containing the geometry to the job\n",
    "    geometry = geojson.loads(row.geometry)\n",
    "    assert isinstance(geometry, geojson.FeatureCollection)\n",
    "\n",
    "    # Filter the geometry to the rows with the extract only flag\n",
    "    geometry = filter_extractonly_geometries(geometry)\n",
    "    assert len(geometry.features) > 0, \"No geometries with the extract flag found\"\n",
    "\n",
    "    # Performs a buffer of 64 px around the geometry\n",
    "    geometry = buffer_geometry(geometry, 319)\n",
    "\n",
    "    # Backend name and fetching type\n",
    "    backend = Backend(row.backend_name)\n",
    "    backend_context = BackendContext(backend)\n",
    "\n",
    "    fetch_type = FetchType.POLYGON\n",
    "    bands_to_download = ['S2-B01', 'S2-B02', 'S2-B03', 'S2-B04', 'S2-B05', 'S2-B06', 'S2-B07', 'S2-B08', 'S2-B8A', 'S2-B09', 'S2-B11', 'S2-B12', 'S2-SCL']\n",
    "\n",
    "    # Create the job to extract S2\n",
    "    extraction_parameters = {\n",
    "        \"target_resolution\": 10\n",
    "    }\n",
    "    extractor = build_sentinel2_l2a_extractor(\n",
    "        backend_context, bands=bands_to_download, fetch_type=fetch_type.POLYGON, **extraction_parameters \n",
    "    )\n",
    "\n",
    "    cube = extractor.get_cube(connection, geometry, temporal_context)\n",
    "\n",
    "    # Get the h3index to use in the tile\n",
    "    h3index = geometry.features[0].properties['h3index']\n",
    "    valid_date = geometry.features[0].properties['valid_date']\n",
    "\n",
    "    # Increase the memory of the jobs\n",
    "    job_options = {\n",
    "        \"executor-memory\": \"5G\",\n",
    "        \"executor-memoryOverhead\": \"2G\",\n",
    "    }\n",
    "\n",
    "    return cube.create_job(\n",
    "        out_format=\"NetCDF\",\n",
    "        title=f\"GFMAP_Extraction_S2_{h3index}_{valid_date}\",\n",
    "        sample_by_feature=True,\n",
    "        job_options=job_options\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth step: create output paths\n",
    "\n",
    "Implement a function that from a temporary path containing a job result, from the job dataframe row and the root folder will choose the output path where to save that job result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.25 s, sys: 13.8 ms, total: 2.27 s\n",
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load the S2 grid\n",
    "s2_grid = gpd.read_file('./s2grid_bounds.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "from pyproj import Transformer, CRS\n",
    "from shapely.geometry import box, Point\n",
    "\n",
    "def generate_output_path_s2(root_folder: Path, tmp_path: Path, geometry_index: int, row: pd.Series):\n",
    "    features = geojson.loads(row.geometry)\n",
    "    sample_id = features[geometry_index].properties['sample_id']\n",
    "    ref_id = features[geometry_index].properties['ref_id']\n",
    "    \n",
    "    # Loads the array lazily in-memory\n",
    "    try:\n",
    "        inds = xr.open_dataset(tmp_path, chunks='auto')\n",
    "        \n",
    "        source_crs = CRS.from_wkt(inds.crs.attrs['crs_wkt'])\n",
    "        dst_crs = CRS.from_epsg(4326)\n",
    "        \n",
    "        transformer = Transformer.from_crs(source_crs, dst_crs, always_xy=True)\n",
    "        bounds = inds.x.min().item(), inds.y.min().item(), inds.x.max().item(), inds.y.max().item()\n",
    "        bbox = box(*bounds)\n",
    "\n",
    "        # Get the center of the box\n",
    "        centroid = bbox.centroid\n",
    "        lon, lat = transformer.transform(centroid.x, centroid.y)\n",
    "        centroid_pt = Point(lon, lat)\n",
    "\n",
    "        # Intersecting with the s2 grid\n",
    "        intersecting = s2_grid.geometry.intersects(centroid_pt)\n",
    "\n",
    "        # Select the intersecting cell that has a centroid the closest from the point\n",
    "        intersecting_cells = s2_grid[intersecting]\n",
    "        intersecting_cells['distance'] = intersecting_cells.distance(centroid_pt)\n",
    "        intersecting_cells.sort_values('distance', inplace=True)\n",
    "        s2_tile = intersecting_cells.iloc[0]\n",
    "\n",
    "        s2_tile_id = s2_tile.tile\n",
    "\n",
    "        subfolder = root_folder / ref_id / str(source_crs.to_epsg()) / s2_tile_id / sample_id\n",
    "    except Exception:\n",
    "        # TODO: _log.error('Could not find S2 tile for file, setting up a dummy path')\n",
    "        subfolder = root_folder / 'unsortable'\n",
    "\n",
    "    return subfolder / f'{row.out_prefix}_{sample_id}_{source_crs.to_epsg()}_{row.start_date}_{row.end_date}{row.out_extension}'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth step: Define the post-job action\n",
    "\n",
    "The post-job action will be called once the job resut was downloaded and saved to a specific path.\n",
    "\n",
    "A post-job action function must receive 3 parameters:\n",
    "* `result_paths`: Paths to the downloaded job result files.\n",
    "* `row`: The current job dataframe row.\n",
    "* `parameters`: User-defined parameters set in the `GFMAPJobManager` constructor.\n",
    "\n",
    "The post-job action must return a list of paths containing the results from that job. For example, if no file is created/deleted in the post-job action, then the user can simply return the list of paths it has received as input `result_paths`. If instead files are added or removed, then the user will need to modify this list accordingly before returning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_bounds\n",
    "import json\n",
    "\n",
    "def post_job_action(result_paths: dict, row: pd.Series, parameters: dict = {}) -> list:\n",
    "    base_gpd = gpd.GeoDataFrame.from_features(json.loads(row.geometry)).set_crs(epsg=4326)\n",
    "    assert len(base_gpd[base_gpd.extract == True]) == len(result_paths), \"The number of result paths should be the same as the number of geometries\"\n",
    "    extracted_gpd = base_gpd[base_gpd.extract == True].reset_index(drop=True)\n",
    "    # In this case we want to burn the metadata in a new file in the same folder as the S2 product\n",
    "    for idx, result_path in enumerate(result_paths.copy()):\n",
    "        sample_id = extracted_gpd.iloc[idx].sample_id\n",
    "        ref_id = extracted_gpd.iloc[idx].ref_id\n",
    "        lc_label = extracted_gpd.iloc[idx].landcover_label\n",
    "        confidence = extracted_gpd.iloc[idx].confidence\n",
    "        valid_date = extracted_gpd.iloc[idx].valid_date\n",
    "\n",
    "        result_ds = xr.open_dataset(result_path, chunks='auto')\n",
    "\n",
    "        target_crs = CRS.from_wkt(result_ds.crs.attrs['crs_wkt'])\n",
    "\n",
    "        # Get the surrounding polygons around our extracted center geometry to rastetize them\n",
    "        bounds = (result_ds.x.min().item(), result_ds.y.min().item(), result_ds.x.max().item(), result_ds.y.max().item())\n",
    "        bbox = box(*bounds)\n",
    "        surround_gpd = base_gpd.to_crs(target_crs).clip(bbox)\n",
    "\n",
    "        # Burn the polygon croptypes\n",
    "        transform = from_bounds(*bounds, result_ds.x.size, result_ds.y.size)\n",
    "        croptype_shapes = list(zip(surround_gpd.geometry, surround_gpd.croptype_label))\n",
    "        croptype = rasterize(croptype_shapes, out_shape=(result_ds.y.size, result_ds.x.size), transform=transform, all_touched=True, fill=0, default_value=65535, dtype='uint16')\n",
    "\n",
    "        # Create the attributes to add to the metadata\n",
    "        crs_layer = result_ds['crs']\n",
    "        attributes = {\n",
    "            'ref_id': ref_id,\n",
    "            'sample_id': sample_id,\n",
    "            'landcover_label': lc_label,\n",
    "            'confidence': str(confidence),\n",
    "            'valid_date': valid_date\n",
    "        }\n",
    "        attributes.update(result_ds.attrs)\n",
    "\n",
    "        aux_dataset = xr.Dataset({'CROPTYPE': (('y', 'x'), croptype)}, coords={'y': result_ds.y, 'x': result_ds.x}, attrs=attributes)\n",
    "\n",
    "        # Include the CRS layer from OpenEO\n",
    "        aux_dataset['crs'] = crs_layer\n",
    "        aux_dataset.attrs.update(result_ds.attrs)\n",
    "\n",
    "        # Save the metadata in the same folder as the S2 product\n",
    "        metadata_path = result_path.parent / f'AUX_{sample_id}_{target_crs.to_epsg()}_{valid_date}.nc'\n",
    "        aux_dataset.to_netcdf(metadata_path, format='NETCDF4', engine='h5netcdf')\n",
    "        result_paths.append(metadata_path)\n",
    "\n",
    "    return result_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sixth and last step: Running the manager\n",
    "\n",
    "Let's initialize and execute the Job Manager as defined the GFMAP, and then run it using the functions defined previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo_gfmap.manager.job_manager import GFMAPJobManager\n",
    "from openeo_gfmap.backend import cdse_staging_connection\n",
    "\n",
    "base_output_dir = Path('/data/users/Public/vincent.verelst/world_cereal/extractions/')\n",
    "tracking_job_csv = base_output_dir / 'job_tracker.csv'\n",
    "\n",
    "manager = GFMAPJobManager(\n",
    "    output_dir=base_output_dir,\n",
    "    output_path_generator=generate_output_path_s2,\n",
    "    # post_job_action=post_job_action,\n",
    "    poll_sleep=60,\n",
    "    n_threads=2,\n",
    "    post_job_params={}\n",
    ")\n",
    "\n",
    "manager.add_backend(\n",
    "    Backend.CDSE_STAGING.value, cdse_staging_connection, parallel_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 16:05:44,792|openeo_gfmap.manager|INFO:  Starting job manager using 2 worker threads.\n",
      "2024-02-27 16:05:44,792|openeo_gfmap.manager|INFO:  Starting job manager using 2 worker threads.\n",
      "2024-02-27 16:05:44,794|openeo_gfmap.manager|INFO:  Workers started, creating and running jobs.\n",
      "2024-02-27 16:05:44,794|openeo_gfmap.manager|INFO:  Workers started, creating and running jobs.\n",
      "2024-02-27 16:05:44,833|openeo_gfmap.manager|DEBUG:  Normalizing dataframe. Columns: Index(['backend_name', 'out_prefix', 'out_extension', 'start_date', 'end_date',\n",
      "       'geometry', 'status', 'id', 'start_time', 'cpu', 'memory', 'duration',\n",
      "       'description', 'costs'],\n",
      "      dtype='object')\n",
      "2024-02-27 16:05:44,833|openeo_gfmap.manager|DEBUG:  Normalizing dataframe. Columns: Index(['backend_name', 'out_prefix', 'out_extension', 'start_date', 'end_date',\n",
      "       'geometry', 'status', 'id', 'start_time', 'cpu', 'memory', 'duration',\n",
      "       'description', 'costs'],\n",
      "      dtype='object')\n",
      "2024-02-27 16:05:44,836|openeo_gfmap.manager|DEBUG:  Updating status. 0 on 1 active jobs...\n",
      "2024-02-27 16:05:44,836|openeo_gfmap.manager|DEBUG:  Updating status. 0 on 1 active jobs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n",
      "DataCube(<PGNode 'dimension_labels' at 0x7fe3a5cdf4f0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 16:07:07,061|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:07:07,061|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:07:07,428|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:07:07,428|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:08:07,667|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:08:07,667|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:08:08,026|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:08:08,026|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:09:08,250|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:09:08,250|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:09:08,471|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:09:08,471|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:10:08,771|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:10:08,771|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:10:29,051|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:10:29,051|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:11:29,268|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:11:29,268|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:11:29,712|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:11:29,712|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:12:29,938|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:12:29,938|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:12:31,014|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:12:31,014|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:13:31,205|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:13:31,205|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:13:32,004|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:13:32,004|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:14:32,246|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:14:32,246|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:14:34,205|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:14:34,205|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:15:34,551|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:15:34,551|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:15:35,131|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:15:35,131|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is running (on backend cdse-staging).\n",
      "2024-02-27 16:16:35,369|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:16:35,369|openeo_gfmap.manager|DEBUG:  Updating status. 1 on 1 active jobs...\n",
      "2024-02-27 16:16:35,931|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is finished (on backend cdse-staging).\n",
      "2024-02-27 16:16:35,931|openeo_gfmap.manager|DEBUG:  Status of job j-2402271caa2647f79d54a51caddf1388 is finished (on backend cdse-staging).\n",
      "2024-02-27 16:16:35,933|openeo_gfmap.manager|INFO:  Job j-2402271caa2647f79d54a51caddf1388 finished successfully, queueing on_job_done...\n",
      "2024-02-27 16:16:35,933|openeo_gfmap.manager|INFO:  Job j-2402271caa2647f79d54a51caddf1388 finished successfully, queueing on_job_done...\n",
      "2024-02-27 16:16:35,937|openeo_gfmap.manager|DEBUG:  Worker thread Thread-7: polled finished job with status PostJobStatus.FINISHED.\n",
      "2024-02-27 16:16:35,937|openeo_gfmap.manager|DEBUG:  Worker thread Thread-7: polled finished job with status PostJobStatus.FINISHED.\n",
      "2024-02-27 16:16:37,248|openeo_gfmap.manager|DEBUG:  Downloading asset openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388 -> /tmp/tmptvay9e8n\n",
      "2024-02-27 16:16:37,248|openeo_gfmap.manager|DEBUG:  Downloading asset openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388 -> /tmp/tmptvay9e8n\n",
      "2024-02-27 16:16:50,232|openeo_gfmap.manager|DEBUG:  Generating output path for asset openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388...\n",
      "2024-02-27 16:16:50,232|openeo_gfmap.manager|DEBUG:  Generating output path for asset openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388...\n",
      "/tmp/ipykernel_40766/1596858655.py:32: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  intersecting_cells['distance'] = intersecting_cells.distance(centroid_pt)\n",
      "/home/vverelst/anaconda3/envs/openeo-dev/lib/python3.9/site-packages/geopandas/geodataframe.py:1525: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/tmp/ipykernel_40766/1596858655.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  intersecting_cells.sort_values('distance', inplace=True)\n",
      "2024-02-27 16:16:50,617|openeo_gfmap.manager|DEBUG:  Generated path for asset openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VMD/2021_LV_LPIS_POLY_110-12880341/S2_2021_LV_LPIS_POLY_110-12880341_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:16:50,617|openeo_gfmap.manager|DEBUG:  Generated path for asset openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VMD/2021_LV_LPIS_POLY_110-12880341/S2_2021_LV_LPIS_POLY_110-12880341_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:16:52,422|openeo_gfmap.manager|INFO:  Downloaded asset openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VMD/2021_LV_LPIS_POLY_110-12880341/S2_2021_LV_LPIS_POLY_110-12880341_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:16:52,422|openeo_gfmap.manager|INFO:  Downloaded asset openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VMD/2021_LV_LPIS_POLY_110-12880341/S2_2021_LV_LPIS_POLY_110-12880341_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:16:52,428|openeo_gfmap.manager|DEBUG:  Downloading asset openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388 -> /tmp/tmplpt96uvh\n",
      "2024-02-27 16:16:52,428|openeo_gfmap.manager|DEBUG:  Downloading asset openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388 -> /tmp/tmplpt96uvh\n",
      "2024-02-27 16:17:06,168|openeo_gfmap.manager|DEBUG:  Generating output path for asset openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388...\n",
      "2024-02-27 16:17:06,168|openeo_gfmap.manager|DEBUG:  Generating output path for asset openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388...\n",
      "/tmp/ipykernel_40766/1596858655.py:32: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  intersecting_cells['distance'] = intersecting_cells.distance(centroid_pt)\n",
      "/home/vverelst/anaconda3/envs/openeo-dev/lib/python3.9/site-packages/geopandas/geodataframe.py:1525: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/tmp/ipykernel_40766/1596858655.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  intersecting_cells.sort_values('distance', inplace=True)\n",
      "2024-02-27 16:17:06,235|openeo_gfmap.manager|DEBUG:  Generated path for asset openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VMD/2021_LV_LPIS_POLY_110-12525751/S2_2021_LV_LPIS_POLY_110-12525751_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:17:06,235|openeo_gfmap.manager|DEBUG:  Generated path for asset openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VMD/2021_LV_LPIS_POLY_110-12525751/S2_2021_LV_LPIS_POLY_110-12525751_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:17:07,647|openeo_gfmap.manager|INFO:  Downloaded asset openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VMD/2021_LV_LPIS_POLY_110-12525751/S2_2021_LV_LPIS_POLY_110-12525751_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:17:07,647|openeo_gfmap.manager|INFO:  Downloaded asset openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VMD/2021_LV_LPIS_POLY_110-12525751/S2_2021_LV_LPIS_POLY_110-12525751_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:17:07,653|openeo_gfmap.manager|DEBUG:  Downloading asset openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388 -> /tmp/tmpgty_rrsp\n",
      "2024-02-27 16:17:07,653|openeo_gfmap.manager|DEBUG:  Downloading asset openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388 -> /tmp/tmpgty_rrsp\n",
      "2024-02-27 16:17:18,496|openeo_gfmap.manager|DEBUG:  Generating output path for asset openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388...\n",
      "2024-02-27 16:17:18,496|openeo_gfmap.manager|DEBUG:  Generating output path for asset openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388...\n",
      "/tmp/ipykernel_40766/1596858655.py:32: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  intersecting_cells['distance'] = intersecting_cells.distance(centroid_pt)\n",
      "/home/vverelst/anaconda3/envs/openeo-dev/lib/python3.9/site-packages/geopandas/geodataframe.py:1525: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/tmp/ipykernel_40766/1596858655.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  intersecting_cells.sort_values('distance', inplace=True)\n",
      "2024-02-27 16:17:18,547|openeo_gfmap.manager|DEBUG:  Generated path for asset openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VND/2021_LV_LPIS_POLY_110-12440159/S2_2021_LV_LPIS_POLY_110-12440159_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:17:18,547|openeo_gfmap.manager|DEBUG:  Generated path for asset openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VND/2021_LV_LPIS_POLY_110-12440159/S2_2021_LV_LPIS_POLY_110-12440159_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:17:19,835|openeo_gfmap.manager|INFO:  Downloaded asset openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VND/2021_LV_LPIS_POLY_110-12440159/S2_2021_LV_LPIS_POLY_110-12440159_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:17:19,835|openeo_gfmap.manager|INFO:  Downloaded asset openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388 -> /data/users/Public/vincent.verelst/world_cereal/extractions/2021_EUR_DEMO_POLY_110/32635/35VND/2021_LV_LPIS_POLY_110-12440159/S2_2021_LV_LPIS_POLY_110-12440159_32635_2020-08-30_2022-03-03.nc\n",
      "2024-02-27 16:17:25,452|openeo_gfmap.manager|INFO:  Added item j-2402271caa2647f79d54a51caddf1388_openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388 to STAC collection\n",
      "2024-02-27 16:17:25,452|openeo_gfmap.manager|INFO:  Added item j-2402271caa2647f79d54a51caddf1388_openEO_0.nc from job j-2402271caa2647f79d54a51caddf1388 to STAC collection\n",
      "2024-02-27 16:17:27,674|openeo_gfmap.manager|INFO:  Added item j-2402271caa2647f79d54a51caddf1388_openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388 to STAC collection\n",
      "2024-02-27 16:17:27,674|openeo_gfmap.manager|INFO:  Added item j-2402271caa2647f79d54a51caddf1388_openEO_1.nc from job j-2402271caa2647f79d54a51caddf1388 to STAC collection\n",
      "2024-02-27 16:17:30,851|openeo_gfmap.manager|INFO:  Added item j-2402271caa2647f79d54a51caddf1388_openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388 to STAC collection\n",
      "2024-02-27 16:17:30,851|openeo_gfmap.manager|INFO:  Added item j-2402271caa2647f79d54a51caddf1388_openEO_2.nc from job j-2402271caa2647f79d54a51caddf1388 to STAC collection\n",
      "2024-02-27 16:17:30,856|openeo_gfmap.manager|INFO:  Job j-2402271caa2647f79d54a51caddf1388 and post job action finished successfully.\n",
      "2024-02-27 16:17:30,856|openeo_gfmap.manager|INFO:  Job j-2402271caa2647f79d54a51caddf1388 and post job action finished successfully.\n"
     ]
    }
   ],
   "source": [
    "manager.run_jobs(job_df, create_datacube_s2, tracking_job_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the STAC collection to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.create_stac()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openeo-dev",
   "language": "python",
   "name": "openeo-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
