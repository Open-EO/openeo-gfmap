{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTC Load test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/gfmap/DEMO_CROPTYPE.gpkg\"\n",
    "output_path = '/data/users/Public/vincent.verelst/otc_load_test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the logging module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the logging for the openeo_gfmap package\n",
    "from openeo_gfmap.manager import _log\n",
    "import logging\n",
    "\n",
    "_log.setLevel(logging.DEBUG)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "_log.addHandler(stream_handler)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s|%(name)s|%(levelname)s:  %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "# Exclude the other loggers from other libraries\n",
    "class MyLoggerFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.name == _log.name\n",
    "\n",
    "stream_handler.addFilter(MyLoggerFilter())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step: splitting the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vverelst/openeo/openeo-gfmap/src/openeo_gfmap/manager/job_splitters.py:65: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  polygons[\"geometry\"] = polygons.geometry.centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 sub-datasets.\n",
      "87 sub-datasets after filtering sub-datasets with no point to extract.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vverelst/openeo/openeo-gfmap/src/openeo_gfmap/manager/job_splitters.py:69: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  s2_grid[\"geometry\"] = s2_grid.geometry.centroid\n",
      "/home/vverelst/anaconda3/envs/openeo-gfmap/lib/python3.9/site-packages/geopandas/array.py:365: UserWarning: Geometry is in a geographic CRS. Results from 'sjoin_nearest' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from openeo_gfmap.manager.job_splitters import split_job_s2grid\n",
    "\n",
    "base_df_path = input_df\n",
    "base_df = gpd.read_file(base_df_path)\n",
    "# Splits the job using GFMAP\n",
    "split_jobs = split_job_s2grid(\n",
    "    base_df, max_points=200\n",
    ")\n",
    "\n",
    "print(f'{len(split_jobs)} sub-datasets.')\n",
    "\n",
    "# Remove the geometry where there are no points with the \"extract\" flag\n",
    "split_jobs = [\n",
    "    job for job in split_jobs if job.extract.any()\n",
    "]\n",
    "print(f'{len(split_jobs)} sub-datasets after filtering sub-datasets with no point to extract.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second step: creating a dataframe for the GFMAP Job Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend_name</th>\n",
       "      <th>out_extension</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>s2_tile</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>31UDS</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>31UES</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>31UFS</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>32TPT</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>33TVM</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>35VNC</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>35VNC</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>35VNC</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>35VND</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>35VND</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   backend_name out_extension  start_date    end_date s2_tile  \\\n",
       "0           otc      .parquet  2020-08-30  2022-03-03   31UDS   \n",
       "1           otc      .parquet  2020-08-30  2022-03-03   31UES   \n",
       "2           otc      .parquet  2020-08-30  2022-03-03   31UFS   \n",
       "3           otc      .parquet  2020-08-30  2022-03-03   32TPT   \n",
       "4           otc      .parquet  2020-08-30  2022-03-03   33TVM   \n",
       "..          ...           ...         ...         ...     ...   \n",
       "82          otc      .parquet  2020-08-30  2022-03-03   35VNC   \n",
       "83          otc      .parquet  2020-08-30  2022-03-03   35VNC   \n",
       "84          otc      .parquet  2020-08-30  2022-03-03   35VNC   \n",
       "85          otc      .parquet  2020-08-30  2022-03-03   35VND   \n",
       "86          otc      .parquet  2020-08-30  2022-03-03   35VND   \n",
       "\n",
       "                                             geometry  \n",
       "0   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "1   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "2   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "3   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "4   {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "..                                                ...  \n",
       "82  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "83  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "84  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "85  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "86  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "\n",
       "[87 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openeo_gfmap import Backend\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "def create_job_dataframe(\n",
    "    backend: Backend, split_jobs: List[gpd.GeoDataFrame]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Create a dataframe from the split jobs, containg all the necessary information to run the job.\"\"\"\n",
    "    columns = [\n",
    "        \"backend_name\",\n",
    "        \"out_extension\",\n",
    "        \"start_date\",\n",
    "        \"end_date\",\n",
    "        \"s2_tile\",\n",
    "        \"geometry\",\n",
    "    ]\n",
    "    rows = []\n",
    "    for job in split_jobs:\n",
    "        # Compute the average in the valid date and make a buffer of 1.5 year around\n",
    "        median_time = pd.to_datetime(job.valid_date).mean()\n",
    "        start_date = median_time - pd.Timedelta(days=275)  # A bit more than 9 months\n",
    "        end_date = median_time + pd.Timedelta(days=275)  # A bit more than 9 months\n",
    "        s2_tile = job.tile.iloc[0]\n",
    "        rows.append(\n",
    "            pd.Series(\n",
    "                dict(\n",
    "                    zip(\n",
    "                        columns,\n",
    "                        [\n",
    "                            backend.value,\n",
    "                            \".parquet\",\n",
    "                            start_date.strftime(\"%Y-%m-%d\"),\n",
    "                            end_date.strftime(\"%Y-%m-%d\"),\n",
    "                            s2_tile,\n",
    "                            job.to_json(),\n",
    "                        ],\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "job_df = create_job_dataframe(Backend.OTC, split_jobs)\n",
    "\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-sampling job dataframe to reduce execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = job_df.iloc[[2]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend_name</th>\n",
       "      <th>out_extension</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>s2_tile</th>\n",
       "      <th>geometry</th>\n",
       "      <th>nb_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>otc</td>\n",
       "      <td>.parquet</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>31UFS</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  backend_name out_extension  start_date    end_date s2_tile  \\\n",
       "0          otc      .parquet  2020-08-30  2022-03-03   31UFS   \n",
       "\n",
       "                                            geometry  nb_points  \n",
       "0  {\"type\": \"FeatureCollection\", \"features\": [{\"i...          3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geojson\n",
    "\n",
    "def get_job_nb_points(row: pd.Series) -> int:\n",
    "    \"\"\"Get the number of polygons in the geometry.\"\"\"\n",
    "    return len(list(filter(lambda feat: feat.properties.get(\"extract\"), geojson.loads(row.geometry)['features'])))\n",
    "\n",
    "job_df['nb_points'] = job_df.apply(get_job_nb_points, axis=1)\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third step: implement the datacube creator function.\n",
    "\n",
    "Implement a function to create, from the additional rows provided before, an `openeo.BatchJob` that will be used to run the job.\n",
    "\n",
    "In this case we extract Sentinel-2 data around a 64x64 pixel square of polygons which have the field `extract=True` (although we keep them in the row for the post-job action.)\n",
    "\n",
    "Note:\n",
    "Because the polygons to extract are specified in UTM dimensions (required to have a specific size), the dataset of polygon cannot be send directly through the openeo process graph (GeoJSON only support lat/lon coordinates). The sub-datasets of polygons are therefore uploaded to a publicly accessible URL so they can be used later by openeo during the execution of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "from openeo import UDF, Connection, DataCube\n",
    "from openeo_gfmap import (\n",
    "    BackendContext,\n",
    "    BoundingBoxExtent,\n",
    "    FetchType,\n",
    "    SpatialContext,\n",
    "    TemporalContext,\n",
    ")\n",
    "from openeo_gfmap.fetching.generic import build_generic_extractor\n",
    "from openeo_gfmap.fetching.s1 import build_sentinel1_grd_extractor\n",
    "from openeo_gfmap.fetching.s2 import build_sentinel2_l2a_extractor\n",
    "from openeo_gfmap.preprocessing.compositing import (\n",
    "    max_ndvi_compositing,\n",
    "    mean_compositing,\n",
    ")\n",
    "from openeo_gfmap.preprocessing.interpolation import linear_interpolation\n",
    "from openeo_gfmap.preprocessing.sar import compress_backscatter_uint16\n",
    "\n",
    "def raw_datacube_S2(\n",
    "    connection: Connection,\n",
    "    backend_context: BackendContext,\n",
    "    spatial_extent: SpatialContext,\n",
    "    temporal_extent: TemporalContext,\n",
    "    bands: List[str],\n",
    "    fetch_type: FetchType,\n",
    "    filter_tile: Optional[str] = None,\n",
    "    distance_to_cloud_flag: Optional[bool] = True,\n",
    "    additional_masks_flag: bool = True,\n",
    "    apply_mask_flag: bool = False,\n",
    ") -> DataCube:\n",
    "    \"\"\"Extract Sentinel-2 datacube from OpenEO using GFMAP routines.\n",
    "    Raw data is extracted with no cloud masking applied by default (can be\n",
    "    enabled by setting `apply_mask=True`). In additional to the raw band values\n",
    "    a cloud-mask computed from the dilation of the SCL layer, as well as a\n",
    "    rank mask from the BAP compositing are added.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    connection : Connection\n",
    "        OpenEO connection instance.\n",
    "    backend_context : BackendContext\n",
    "        GFMAP Backend context to use for extraction.\n",
    "    spatial_extent : SpatialContext\n",
    "        Spatial context to extract data from, can be a GFMAP BoundingBoxExtent,\n",
    "        a GeoJSON dict or an URL to a publicly accessible GeoParquet file.\n",
    "    temporal_extent : TemporalContext\n",
    "        Temporal context to extract data from.\n",
    "    bands : List[str]\n",
    "        List of Sentinel-2 bands to extract.\n",
    "    fetch_type : FetchType\n",
    "        GFMAP Fetch type to use for extraction.\n",
    "    filter_tile : Optional[str], optional\n",
    "        Filter by tile ID, by default disabled. This forces the process to only\n",
    "        one tile ID from the Sentinel-2 collection.\n",
    "    distance_to_cloud_flag : Optional[bool], optional\n",
    "        Compute the distance to cloud, by default True.\n",
    "    additional_masks_flag : bool, optional\n",
    "        Add the additional masks to the cube, by default True. This includes the\n",
    "        distance to cloud and the SCL dilation mask.\n",
    "    apply_mask_flag : bool, optional\n",
    "        Apply cloud masking, by default False. Can be enabled for high\n",
    "        optimization of memory usage.\n",
    "    \"\"\"\n",
    "    # Extract the SCL collection only\n",
    "    scl_cube_properties = {\"eo:cloud_cover\": lambda val: val <= 95.0}\n",
    "    if filter_tile:\n",
    "        scl_cube_properties[\"tileId\"] = lambda val: val == filter_tile\n",
    "\n",
    "    scl_cube = connection.load_collection(\n",
    "        collection_id=\"SENTINEL2_L2A\",\n",
    "        bands=[\"SCL\"],\n",
    "        temporal_extent=[temporal_extent.start_date, temporal_extent.end_date],\n",
    "        spatial_extent=dict(spatial_extent) if fetch_type == FetchType.TILE else None,\n",
    "        properties=scl_cube_properties,\n",
    "    )\n",
    "\n",
    "    # Resample to 10m resolution for the SCL layer\n",
    "    scl_cube = scl_cube.resample_spatial(10)\n",
    "\n",
    "    # Compute the SCL dilation mask\n",
    "    scl_dilated_mask = scl_cube.process(\n",
    "        \"to_scl_dilation_mask\",\n",
    "        data=scl_cube,\n",
    "        scl_band_name=\"SCL\",\n",
    "        kernel1_size=17,  # 17px dilation on a 10m layer\n",
    "        kernel2_size=77,  # 77px dilation on a 10m layer\n",
    "        mask1_values=[2, 4, 5, 6, 7],\n",
    "        mask2_values=[3, 8, 9, 10, 11],\n",
    "        erosion_kernel_size=3,\n",
    "    ).rename_labels(\"bands\", [\"S2-L2A-SCL_DILATED_MASK\"])\n",
    "\n",
    "    additional_masks = scl_dilated_mask\n",
    "\n",
    "    if distance_to_cloud_flag:\n",
    "        # Compute the distance to cloud and add it to the cube\n",
    "        distance_to_cloud = scl_cube.apply_neighborhood(\n",
    "            process=UDF.from_file(Path(__file__).parent / \"udf_distance_to_cloud.py\"),\n",
    "            size=[\n",
    "                {\"dimension\": \"x\", \"unit\": \"px\", \"value\": 256},\n",
    "                {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 256},\n",
    "                {\"dimension\": \"t\", \"unit\": \"null\", \"value\": \"P1D\"},\n",
    "            ],\n",
    "            overlap=[\n",
    "                {\"dimension\": \"x\", \"unit\": \"px\", \"value\": 16},\n",
    "                {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 16},\n",
    "            ],\n",
    "        ).rename_labels(\"bands\", [\"S2-L2A-DISTANCE-TO-CLOUD\"])\n",
    "\n",
    "        additional_masks = scl_dilated_mask.merge_cubes(distance_to_cloud)\n",
    "\n",
    "    # Try filtering using the geometry\n",
    "    if fetch_type == FetchType.TILE:\n",
    "        additional_masks = additional_masks.filter_spatial(spatial_extent.to_geojson())\n",
    "\n",
    "    # Create the job to extract S2\n",
    "    extraction_parameters = {\n",
    "        \"target_resolution\": None,  # Disable target resolution\n",
    "        \"load_collection\": {\n",
    "            \"eo:cloud_cover\": lambda val: val <= 95.0,\n",
    "        },\n",
    "    }\n",
    "    if additional_masks_flag:\n",
    "        extraction_parameters[\"pre_merge\"] = additional_masks\n",
    "    if filter_tile:\n",
    "        extraction_parameters[\"load_collection\"][\"tileId\"] = (\n",
    "            lambda val: val == filter_tile\n",
    "        )\n",
    "    if apply_mask_flag:\n",
    "        extraction_parameters[\"pre_mask\"] = scl_dilated_mask\n",
    "\n",
    "    extractor = build_sentinel2_l2a_extractor(\n",
    "        backend_context,\n",
    "        bands=bands,\n",
    "        fetch_type=fetch_type,\n",
    "        **extraction_parameters,\n",
    "    )\n",
    "\n",
    "    return extractor.get_cube(connection, spatial_extent, temporal_extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "\n",
    "import requests\n",
    "from tempfile import NamedTemporaryFile\n",
    "import os\n",
    "import pandas as pd\n",
    "import geojson\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from openeo_gfmap import TemporalContext, Backend, BackendContext, FetchType, SpatialContext\n",
    "from openeo_gfmap.fetching import build_sentinel2_l2a_extractor\n",
    "from openeo_gfmap.preprocessing import linear_interpolation, median_compositing\n",
    "\n",
    "def filter_extract_true(\n",
    "    geometries: geojson.FeatureCollection,\n",
    ") -> geojson.FeatureCollection:\n",
    "    \"\"\"Remove all the geometries from the Feature Collection that have the property field `extract` set to `False`\"\"\"\n",
    "    return geojson.FeatureCollection(\n",
    "        [f for f in geometries.features if f.properties.get(\"extract\", 0) == 1]\n",
    "    )\n",
    "\n",
    "def create_datacube(\n",
    "    row: pd.Series,\n",
    "    connection: openeo.DataCube,\n",
    "    provider,\n",
    "    connection_provider,\n",
    "    executor_memory: str = \"5G\",\n",
    "    executor_memory_overhead: str = \"2G\",\n",
    "):\n",
    "    \"\"\"Creates an OpenEO BatchJob from the given row information.\"\"\"\n",
    "\n",
    "    # Load the temporal and spatial extent\n",
    "    temporal_extent = TemporalContext(row.start_date, row.end_date)\n",
    "    spatial_extent = geojson.loads(row.geometry)\n",
    "\n",
    "    # Get the feature collection containing the geometry to the job\n",
    "    geometry = geojson.loads(row.geometry)\n",
    "    assert isinstance(geometry, geojson.FeatureCollection)\n",
    "\n",
    "    # Filter the geometry to the rows with the extract only flag\n",
    "    geometry = filter_extract_true(geometry)\n",
    "    assert len(geometry.features) > 0, \"No geometries with the extract flag found\"\n",
    "\n",
    "    # Backend name and fetching type\n",
    "    backend = Backend(row.backend_name)\n",
    "    backend_context = BackendContext(backend)\n",
    "\n",
    "    # Select some bands to download (chosen at random at this point)\n",
    "    bands_to_download = [\n",
    "        \"S2-L2A-B04\",\n",
    "        \"S2-L2A-B08\",\n",
    "    ]\n",
    "\n",
    "    fetch_type = FetchType.POINT\n",
    "\n",
    "    cube = raw_datacube_S2(\n",
    "        connection=connection,\n",
    "        backend_context=backend_context,\n",
    "        spatial_extent=spatial_extent,\n",
    "        temporal_extent=temporal_extent,\n",
    "        bands=bands_to_download,\n",
    "        fetch_type=fetch_type,\n",
    "        distance_to_cloud_flag=False,\n",
    "        additional_masks_flag=False,\n",
    "        apply_mask_flag=True,\n",
    "    )\n",
    "\n",
    "    cube = 2.5 * (cube.band('S2-L2A-B08') - cube.band('S2-L2A-B04')) / \\\n",
    "        (cube.band('S2-L2A-B08') + 2.4 * cube.band('S2-L2A-B04') + 1)\n",
    "    cube = cube.add_dimension(\"bands\", 'S2-L2A-EVI', \"bands\")\n",
    "\n",
    "    # Create monthly median composites\n",
    "    cube = median_compositing(cube=cube, period=\"month\")\n",
    "    # Perform linear interpolation\n",
    "    cube = linear_interpolation(cube)\n",
    "\n",
    "    # Finally, create a vector cube based on the Point geometries\n",
    "    cube = cube.aggregate_spatial(geometries=spatial_extent, reducer=\"mean\")\n",
    "\n",
    "    \n",
    "    job_options = {\n",
    "        \"executor-memory\": executor_memory,\n",
    "        \"executor-memoryOverhead\": executor_memory_overhead,\n",
    "    }\n",
    "    return cube.create_job(\n",
    "        out_format=\"Parquet\",\n",
    "        title=f\"GFMAP_Feature_Extraction_S2_{row.s2_tile}\",\n",
    "        job_options=job_options,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth step: create output paths\n",
    "\n",
    "Implement a function that from the sample index the job row determines which path to saves the assets to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo_gfmap.manager.job_splitters import load_s2_grid\n",
    "\n",
    "# Load the S2 grid\n",
    "s2_grid = load_s2_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "\n",
    "def generate_output_path(root_folder: Path, geometry_index: int, row: pd.Series):\n",
    "    features = geojson.loads(row.geometry)\n",
    "    sample_id = features[geometry_index].properties.get(\"sample_id\", None)\n",
    "    if sample_id is None:\n",
    "        sample_id = features[geometry_index].properties[\"sampleID\"]\n",
    "\n",
    "    s2_tile_id = row.s2_tile\n",
    "\n",
    "    subfolder = root_folder / s2_tile_id\n",
    "    return subfolder / f\"{sample_id}{row.out_extension}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sixth and last step: Running the manager\n",
    "\n",
    "Let's initialize and execute the Job Manager as defined the GFMAP, and then run it using the functions defined previously\n",
    "\n",
    "STAC related parameters such as `collection_id` and `collection_description` are also required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 15:16:37,544|openeo_gfmap.manager|INFO:  Starting a fresh STAC collection.\n",
      "2024-06-10 15:16:37,544|openeo_gfmap.manager|INFO:  Starting a fresh STAC collection.\n",
      "2024-06-10 15:16:37,548|openeo_gfmap.manager|INFO:  Starting ThreadPoolExecutor with 2 workers.\n",
      "2024-06-10 15:16:37,548|openeo_gfmap.manager|INFO:  Starting ThreadPoolExecutor with 2 workers.\n",
      "2024-06-10 15:16:37,552|openeo_gfmap.manager|INFO:  Creating and running jobs.\n",
      "2024-06-10 15:16:37,552|openeo_gfmap.manager|INFO:  Creating and running jobs.\n",
      "2024-06-10 15:16:37,594|openeo_gfmap.manager|DEBUG:  Normalizing dataframe. Columns: Index(['backend_name', 'out_extension', 'start_date', 'end_date', 's2_tile',\n",
      "       'geometry', 'nb_points', 'status', 'id', 'start_time', 'cpu', 'memory',\n",
      "       'duration', 'description', 'costs'],\n",
      "      dtype='object')\n",
      "2024-06-10 15:16:37,594|openeo_gfmap.manager|DEBUG:  Normalizing dataframe. Columns: Index(['backend_name', 'out_extension', 'start_date', 'end_date', 's2_tile',\n",
      "       'geometry', 'nb_points', 'status', 'id', 'start_time', 'cpu', 'memory',\n",
      "       'duration', 'description', 'costs'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 15:18:41,836|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:18:41,836|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:19:42,784|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:19:42,784|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:21:09,774|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:21:09,774|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:22:10,511|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:22:10,511|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:23:11,583|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:23:11,583|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:24:56,683|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:24:56,683|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:25:57,767|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:25:57,767|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:26:58,755|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:26:58,755|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:27:59,994|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:27:59,994|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:29:01,006|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:29:01,006|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:31:56,123|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:31:56,123|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:32:57,086|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:32:57,086|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:34:18,640|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:34:18,640|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:35:24,450|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:35:24,450|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:36:25,394|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:36:25,394|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:37:26,300|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:37:26,300|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:38:27,024|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:38:27,024|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:39:28,022|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:39:28,022|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:40:29,871|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:40:29,871|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:41:39,674|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:41:39,674|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:42:40,765|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:42:40,765|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:43:41,806|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:43:41,806|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:44:45,256|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:44:45,256|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:45:46,714|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:45:46,714|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:46:53,826|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:46:53,826|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:47:54,498|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:47:54,498|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:48:55,561|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:48:55,561|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:49:56,343|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:49:56,343|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:51:17,824|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:51:17,824|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:52:18,718|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:52:18,718|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:53:19,561|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:53:19,561|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:54:20,849|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:54:20,849|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is running (on backend otc).\n",
      "2024-06-10 15:55:42,176|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is finished (on backend otc).\n",
      "2024-06-10 15:55:42,176|openeo_gfmap.manager|DEBUG:  Status of job j-2406103019e44272bfb5c77983add778 is finished (on backend otc).\n",
      "2024-06-10 15:55:42,179|openeo_gfmap.manager|INFO:  Job j-2406103019e44272bfb5c77983add778 finished successfully, queueing on_job_done...\n",
      "2024-06-10 15:55:42,179|openeo_gfmap.manager|INFO:  Job j-2406103019e44272bfb5c77983add778 finished successfully, queueing on_job_done...\n",
      "2024-06-10 15:55:43,408|openeo_gfmap.manager|DEBUG:  Generating output path for asset timeseries.parquet from job j-2406103019e44272bfb5c77983add778...\n",
      "2024-06-10 15:55:43,408|openeo_gfmap.manager|DEBUG:  Generating output path for asset timeseries.parquet from job j-2406103019e44272bfb5c77983add778...\n",
      "2024-06-10 15:56:04,864|openeo_gfmap.manager|DEBUG:  Downloaded timeseries.parquet from job j-2406103019e44272bfb5c77983add778 -> /data/users/Public/vincent.verelst/otc_load_test/31UFS/2021_BE_Flanders_full_2195427369.parquet\n",
      "2024-06-10 15:56:04,864|openeo_gfmap.manager|DEBUG:  Downloaded timeseries.parquet from job j-2406103019e44272bfb5c77983add778 -> /data/users/Public/vincent.verelst/otc_load_test/31UFS/2021_BE_Flanders_full_2195427369.parquet\n",
      "2024-06-10 15:56:26,556|openeo_gfmap.manager|INFO:  Adding 0 items to the STAC collection...\n",
      "2024-06-10 15:56:26,556|openeo_gfmap.manager|INFO:  Adding 0 items to the STAC collection...\n",
      "2024-06-10 15:56:26,557|openeo_gfmap.manager|INFO:  Job j-2406103019e44272bfb5c77983add778 and post job action finished successfully.\n",
      "2024-06-10 15:56:26,557|openeo_gfmap.manager|INFO:  Job j-2406103019e44272bfb5c77983add778 and post job action finished successfully.\n",
      "2024-06-10 15:56:42,499|openeo_gfmap.manager|INFO:  Quitting job tracking & waiting for last post-job actions to finish.\n",
      "2024-06-10 15:56:42,499|openeo_gfmap.manager|INFO:  Quitting job tracking & waiting for last post-job actions to finish.\n",
      "2024-06-10 15:56:42,502|openeo_gfmap.manager|INFO:  Exiting ThreadPoolExecutor.\n",
      "2024-06-10 15:56:42,502|openeo_gfmap.manager|INFO:  Exiting ThreadPoolExecutor.\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from openeo_gfmap.manager.job_manager import GFMAPJobManager\n",
    "from openeo_gfmap.backend import otc_connection\n",
    "\n",
    "\n",
    "base_output_dir = Path(output_path)\n",
    "tracking_job_csv = base_output_dir / 'job_tracker.csv'\n",
    "\n",
    "manager = GFMAPJobManager(\n",
    "    output_dir=base_output_dir,\n",
    "    output_path_generator=generate_output_path,\n",
    "    collection_id=\"SENTINEL2_L2A\",\n",
    "    poll_sleep=60,\n",
    "    n_threads=2,\n",
    "    post_job_params={}\n",
    ")\n",
    "\n",
    "manager.add_backend(\n",
    "    Backend.OTC.value, otc_connection, parallel_jobs=6\n",
    ")\n",
    "manager.run_jobs(job_df, create_datacube, tracking_job_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
